{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of loading data and doing some analysis of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is  4177  data in our dataset.\n",
      "There is total  28 different classes and numbers of them\n",
      "9 : 689\n",
      "6 : 259\n",
      "12 : 267\n",
      "16 : 67\n",
      "11 : 487\n",
      "10 : 634\n",
      "17 : 58\n",
      "15 : 103\n",
      "8 : 568\n",
      "14 : 126\n",
      "7 : 391\n",
      "13 : 203\n",
      "5 : 115\n",
      "20 : 26\n",
      "4 : 57\n",
      "3 : 15\n",
      "21 : 14\n",
      "1 : 1\n",
      "18 : 42\n",
      "19 : 32\n",
      "2 : 1\n",
      "26 : 1\n",
      "23 : 9\n",
      "27 : 2\n",
      "24 : 2\n",
      "22 : 6\n",
      "25 : 1\n",
      "29 : 1\n",
      "Feature names are:\n",
      "['Sex', 'Lenght', 'Diameter', 'Height', 'Whole weight', 'Shucked weight', 'Viscera weight', 'Shell weight', 'Rings']\n",
      "Example features are:\n",
      "['F', '0.62', '0.51', '0.175', '1.2705', '0.5415', '0.323', '0.3225']\n",
      "Our attribute vector will be:\n",
      "[0, 1, 1, 1, 1, 1, 1, 1]\n",
      "If we arrange our data with that vector, our data will be:\n",
      "['F', 0.62, 0.51, 0.175, 1.2705, 0.5415, 0.323, 0.3225]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math \n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "\n",
    "def readAbaloneCsv(): # This function is written for leaf.csv, because of order of features and labels\n",
    "    csvOpen = open('abalone.csv')\n",
    "    csvReader = csv.reader(csvOpen) # using csv library to read iris.csv\n",
    "    dataset = []\n",
    "    for row in csvReader:\n",
    "        dataset.append(row) # to csvreader to list\n",
    "    random.shuffle(dataset) # shuffling list for k-fold-validation\n",
    "    dataset_features = []\n",
    "    dataset_labels = []\n",
    "    for data in dataset: # iterating over dataset\n",
    "        label = data.pop(len(data)-1) ## We are droping class and save it to label\n",
    "        dataset_labels.append(label) # saving label to labels\n",
    "        dataset_features.append(data) # saving features but data is full of string, change to float list\n",
    "    return dataset_labels,dataset_features # returning \n",
    "\n",
    "def findLabels(labels): # This function finds how many different labels is there. for confusion matrix\n",
    "    classes = []\n",
    "    for label in labels:\n",
    "        try:\n",
    "            classes.index(label)\n",
    "        except:\n",
    "            classes.append(label)\n",
    "    return classes\n",
    "\n",
    "def countClasses(labels): # This function creates a dictionary of classes and number of them\n",
    "    counts = {}\n",
    "    class_names = findLabels(labels)\n",
    "    for label in labels:\n",
    "        if label not in counts:\n",
    "            counts[label] = 0\n",
    "        counts[label] +=1\n",
    "    return counts\n",
    "\n",
    "def isNumeric(s): # This function finds if the given string is numeric or not\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def findAttributeTypes(features): # This function finds attribute_types of given vector.\n",
    "    attribute_types = []\n",
    "    for col in features:\n",
    "        if(isNumeric(col)):\n",
    "            attribute_types.append(1)\n",
    "        else:\n",
    "            attribute_types.append(0)\n",
    "    return attribute_types\n",
    "\n",
    "def makeNumeric(features,attribute_types): # This function casts all of numeric features.\n",
    "    for col in range(0,len(attribute_types)): # Iterate attribute vector\n",
    "        if attribute_types[col] == 1: # If given attribute is numeric\n",
    "            for row in features:      # Make all this col numeric\n",
    "                row[col] = float(row[col])\n",
    "    return features # Return features\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "labels,features = readAbaloneCsv() # read abolone.csv\n",
    "feature_names = [\"Sex\",\"Lenght\",\"Diameter\",\"Height\",\"Whole weight\",\n",
    "                 \"Shucked weight\",\"Viscera weight\",\"Shell weight\",\"Rings\"]\n",
    "print(\"There is \",len(labels),\" data in our dataset.\")\n",
    "count_classes = countClasses(labels)\n",
    "print(\"There is total \",len(count_classes),\"different classes and numbers of them\")\n",
    "classes = findLabels(labels)\n",
    "for key in count_classes:\n",
    "    print(key,\":\",count_classes[key])\n",
    "print(\"Feature names are:\")\n",
    "print(feature_names)\n",
    "print(\"Example features are:\")\n",
    "attribute_types = findAttributeTypes(features[0])\n",
    "print(features[0])\n",
    "print(\"Our attribute vector will be:\")\n",
    "print(attribute_types)\n",
    "features = makeNumeric(features,attribute_types)\n",
    "print(\"If we arrange our data with that vector, our data will be:\")\n",
    "print(features[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    # End condition for our tree.\n",
    "    # It contains count of class which has impurity equals to 0\n",
    "    def __init__(self,labels):\n",
    "        self.predictions = countClasses(labels)\n",
    "        \n",
    "class Node:\n",
    "    # Decision node for our tree.\n",
    "    # It contains seperator which we use to seperate our data \n",
    "    # And also it contains a true branch if our decision is correct\n",
    "    #                      a false branch if our decision is incorrect\n",
    "    def __init__(self,\n",
    "                 seperator,\n",
    "                 true_branch,\n",
    "                 false_branch):\n",
    "        self.seperator = seperator\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch        \n",
    "\n",
    "        \n",
    "class Seperator:\n",
    "    # This class makes the decision for seperation.\n",
    "    # It contains column (column index of features array, [\"Sex\"=0,\"Lenght\"=1,\"Diameter\"=2,\"Height\"=3,\"Whole weight\"=4,\n",
    "    #             \"Shucked weight\"=5,\"Viscera weight\"=6,\"Shell weight\"=7,\"Rings\"=8])\n",
    "    #             value, value of given column\n",
    "    #             attribute_types, attribute vector\n",
    "    def __init__(self, given_feature, value,attribute_types):\n",
    "        self.column = given_feature\n",
    "        self.value = value\n",
    "        self.attribute_types = attribute_types\n",
    "\n",
    "    def decide(self, example):\n",
    "        # Compare the feature value in an example to the\n",
    "        # feature value in this Seperator.\n",
    "        val = example[self.column]\n",
    "        try:\n",
    "            if self.attribute_types[self.column]==1: # If type is numeric\n",
    "                return val >= self.value\n",
    "            else: # If type is string\n",
    "                return val == self.value\n",
    "        except TypeError:\n",
    "                return val == self.value\n",
    "            \n",
    "def partition(features,labels, seperator): # This function seperates the data, by given seperator\n",
    "    true_features = []\n",
    "    true_labels = []\n",
    "    false_features= []\n",
    "    false_labels = []\n",
    "    for i in range(0,len(features)): # Iterate features and labels\n",
    "        if seperator.decide(features[i]): # If this feature is true\n",
    "            true_features.append(features[i]) # Store them to true ones\n",
    "            true_labels.append(labels[i])\n",
    "        else: # else\n",
    "            false_features.append(features[i]) # Store them to false ones\n",
    "            false_labels.append(labels[i])\n",
    "    return true_features,true_labels,false_features,false_labels # return them\n",
    "\n",
    "def calculateImpurity(labels):\n",
    "    counts = countClasses(labels)\n",
    "    purity = 0\n",
    "    for label in counts:\n",
    "        prob_of_label = counts[label] / float(len(labels))\n",
    "        purity += prob_of_label**2\n",
    "    return 1-purity\n",
    "\n",
    "def gain( true_labels,false_labels, current_uncertainty):\n",
    "    p = float(len(true_labels)) / (len(true_labels) + len(false_labels))\n",
    "    return current_uncertainty - p * calculateImpurity(true_labels) - (1 - p) * calculateImpurity(false_labels)\n",
    "\n",
    "def find_best_split(train_features,train_labels,attribute_types):\n",
    "    best_gain = 0  # keep track of the best information gain\n",
    "    best_seperator = None  # keep train of the feature / value that produced it\n",
    "    current_uncertainty = calculateImpurity(train_labels)\n",
    "    values = []\n",
    "    for col in range(0,len(train_features[0])): # for each feature\n",
    "        #values = set([train_features[col] for row in train_features])  # unique values in the column\n",
    "        values = []\n",
    "        for row in train_features:\n",
    "            try:\n",
    "                values.index(row[col])\n",
    "            except:\n",
    "                values.append(row[col])\n",
    "        for val in values:  # for each value\n",
    "            \n",
    "            seperator = Seperator(col, val,attribute_types)\n",
    "\n",
    "            # try splitting the dataset\n",
    "            true_features,true_labels,false_features,false_labels = partition(train_features,train_labels, seperator)\n",
    "\n",
    "            # Skip this split if it doesn't divide the\n",
    "            # dataset.\n",
    "            if len(true_features) == 0 or len(false_features) == 0:\n",
    "                continue\n",
    "\n",
    "            # Calculate the information gain from this split\n",
    "            gain = gain( true_labels,false_labels, current_uncertainty)\n",
    "\n",
    "            # You actually can use '>' instead of '>=' here\n",
    "            # but I wanted the tree to look a certain way for our\n",
    "            # toy dataset.\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_seperator = gain, seperator\n",
    "\n",
    "    return best_gain, best_seperator\n",
    "\n",
    "def build_dt(X, y, attribute_types, options = 0):\n",
    "    # Try partitioing the dataset on each of the unique attribute,\n",
    "    # calculate the information gain,\n",
    "    # and return the seperator that produces the highest gain.\n",
    "    #print(X,y)\n",
    "    gain, seperator = find_best_split(X,y,attribute_types)\n",
    " \n",
    "    # Base case: no further info gain\n",
    "    # Since we can ask no further seperators,\n",
    "    # we'll return a leaf.\n",
    "    if gain == 0:\n",
    "        return Leaf(y)\n",
    "\n",
    "    # If we reach here, we have found a useful feature / value\n",
    "    # to partition on.\n",
    "    true_features,true_labels,false_features,false_labels = partition(X,y, seperator)\n",
    "\n",
    "    # Recursively build the true branch.\n",
    "    true_branch = build_dt(true_features,true_labels,attribute_types)\n",
    "\n",
    "    # Recursively build the false branch.\n",
    "    false_branch = build_dt(false_features,false_labels,attribute_types)\n",
    "\n",
    "    # Return a seperator node.\n",
    "    # This records the best feature / value to ask at this point,\n",
    "    # as well as the branches to follow\n",
    "    # dependingo on the answer.\n",
    "    return Node(seperator, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of prediction to decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dt(dt, X, options = 0):\n",
    "    predictions = []\n",
    "    for i in range(0,len(X)):\n",
    "        predictions.append(predict(dt,X[i],options))\n",
    "    return predictions\n",
    "\n",
    "def predict(dt, feature, options=0):\n",
    "    \"\"\"See the 'rules of recursion' above.\"\"\"\n",
    "    # Base case: we've reached a leaf\n",
    "    if isinstance(dt, Leaf):\n",
    "        return next(iter(dt.predictions))\n",
    "        \n",
    "    # Decide whether to follow the true-branch or the false-branch.\n",
    "    # Compare the feature / value stored in the node,\n",
    "    # to the example we're considering.\n",
    "    # print(dt.seperator,X[dt.seperator.column])\n",
    "    if dt.seperator.decide(feature):\n",
    "        return predict(dt.true_branch,feature,options)\n",
    "    else:\n",
    "        return predict(dt.false_branch,feature,options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of k-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(labels,features,n,k): # this function splits dataset using k-fold-cross-validation\n",
    "    train_labels = []\n",
    "    train_features = []\n",
    "    test_labels = []\n",
    "    test_features = []\n",
    "\n",
    "    for i in range(0,len(labels)): # iterating dataset\n",
    "        # This condition works like this : goo.gl/images/WNkSSV n is our iteration number k is our splitting factor.\n",
    "        if i >= (len(labels)/k)*(n-1) and i < (len(labels)/k)*(n-1)+len(labels)/k: #splitting test data with n\n",
    "            test_labels.append(labels[i])                                          #nth test data is chosen\n",
    "            test_features.append(features[i])\n",
    "        else:\n",
    "            train_labels.append(labels[i])\n",
    "            train_features.append(features[i])\n",
    "\n",
    "    return train_labels,train_features,test_labels,test_features # returning splitted datas\n",
    "\n",
    "\n",
    "def kfold(k,labels,features,classes,attribute_types):\n",
    "    accuracies = []\n",
    "    result = []\n",
    "    print(\"Dataset will be splitted to \",k,\" equal pieces\")\n",
    "    for i in range(1,k+1): # do k-fold-validation\n",
    "        train_labels,train_features,test_labels,test_features = split(labels,features,i,k)\n",
    "        print(i,\"th/\",k,\" will be used as test data\")\n",
    "        print(\"Train dataset size is\",len(train_labels),\"Test dataset size is\",len(test_labels))\n",
    "        decision_tree = build_dt(train_features, train_labels, attribute_types)\n",
    "        #print(\"Decision tree bitti\",len(test_features),len(test_features[0]))\n",
    "        predictions = predict_dt(decision_tree,test_features)\n",
    "        count=0\n",
    "        for i in range(0,len(predictions)):\n",
    "            if predictions[i]==test_labels[i]:\n",
    "                count+=1\n",
    "        result = count/len(predictions)\n",
    "        print(\"This accuracy is \",result)\n",
    "        accuracies.append(result) # find accuracies\n",
    "    results = 0\n",
    "    for i in range(0,len(accuracies)): # iterating accuracies\n",
    "        results += accuracies[i] # add accuracies\n",
    "    accuracy = results/len(accuracies) # calculate average\n",
    "\n",
    "    print(\"accuracies:\",accuracies)\n",
    "    print(\"Average accuracy:\",accuracy,\"Total samples:\",len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing 5-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold validation for 5\n",
      "Dataset will be splitted to  5  equal pieces\n",
      "1 th/ 5  will be used as test data\n",
      "Train dataset size is 3341 Test dataset size is 836\n",
      "This accuracy is  0.1854066985645933\n",
      "2 th/ 5  will be used as test data\n",
      "Train dataset size is 3342 Test dataset size is 835\n",
      "This accuracy is  0.19041916167664671\n",
      "3 th/ 5  will be used as test data\n",
      "Train dataset size is 3341 Test dataset size is 836\n",
      "This accuracy is  0.2021531100478469\n",
      "4 th/ 5  will be used as test data\n",
      "Train dataset size is 3342 Test dataset size is 835\n",
      "This accuracy is  0.19520958083832335\n",
      "5 th/ 5  will be used as test data\n",
      "Train dataset size is 3342 Test dataset size is 835\n",
      "This accuracy is  0.18682634730538922\n",
      "accuracies: [0.1854066985645933, 0.19041916167664671, 0.2021531100478469, 0.19520958083832335, 0.18682634730538922]\n",
      "Average accuracy: 0.19200297968655988 Total samples: 4177\n"
     ]
    }
   ],
   "source": [
    "print(\"k-fold validation for 5\")    \n",
    "kfold(5,labels,features,classes,attribute_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is pretty low. I think reason for this, we have too many classes but that classes are not represented well.\n",
    "For example class 1 only has 1 data. So we must train tree with more data. For example we will try 10/11 of dataset to train tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing 11-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold validation for 11\n",
      "Dataset will be splitted to  11  equal pieces\n",
      "1 / 11  will be used as test data\n",
      "Train dataset size is 3797 Test dataset size is 380\n",
      "This accuracy is  0.2026315789473684\n",
      "2 / 11  will be used as test data\n",
      "Train dataset size is 3797 Test dataset size is 380\n",
      "This accuracy is  0.18157894736842106\n",
      "3 / 11  will be used as test data\n",
      "Train dataset size is 3797 Test dataset size is 380\n",
      "This accuracy is  0.2\n",
      "4 / 11  will be used as test data\n",
      "Train dataset size is 3798 Test dataset size is 379\n",
      "This accuracy is  0.1820580474934037\n",
      "5 / 11  will be used as test data\n",
      "Train dataset size is 3797 Test dataset size is 380\n",
      "This accuracy is  0.17894736842105263\n",
      "6 / 11  will be used as test data\n",
      "Train dataset size is 3797 Test dataset size is 380\n",
      "This accuracy is  0.22105263157894736\n",
      "7 / 11  will be used as test data\n",
      "Train dataset size is 3797 Test dataset size is 380\n",
      "This accuracy is  0.21842105263157896\n",
      "8 / 11  will be used as test data\n",
      "Train dataset size is 3798 Test dataset size is 379\n",
      "This accuracy is  0.20316622691292877\n",
      "9 / 11  will be used as test data\n",
      "Train dataset size is 3797 Test dataset size is 380\n",
      "This accuracy is  0.1868421052631579\n",
      "10 / 11  will be used as test data\n",
      "Train dataset size is 3797 Test dataset size is 380\n",
      "This accuracy is  0.2131578947368421\n",
      "11 / 11  will be used as test data\n",
      "Train dataset size is 3798 Test dataset size is 379\n",
      "This accuracy is  0.21108179419525067\n",
      "accuracies: [0.2026315789473684, 0.18157894736842106, 0.2, 0.1820580474934037, 0.17894736842105263, 0.22105263157894736, 0.21842105263157896, 0.20316622691292877, 0.1868421052631579, 0.2131578947368421, 0.21108179419525067]\n",
      "Average accuracy: 0.19990342250445012 Total samples: 4177\n"
     ]
    }
   ],
   "source": [
    "print(\"k-fold validation for 11\")    \n",
    "kfold(11,labels,features,classes,attribute_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold validation for 3\n",
      "Dataset will be splitted to  3  equal pieces\n",
      "1 th/ 3  will be used as test data\n",
      "Train dataset size is 2784 Test dataset size is 1393\n",
      "This accuracy is  0.17875089734386218\n",
      "2 th/ 3  will be used as test data\n",
      "Train dataset size is 2785 Test dataset size is 1392\n",
      "This accuracy is  0.1997126436781609\n",
      "3 th/ 3  will be used as test data\n",
      "Train dataset size is 2785 Test dataset size is 1392\n",
      "This accuracy is  0.2025862068965517\n",
      "accuracies: [0.17875089734386218, 0.1997126436781609, 0.2025862068965517]\n",
      "Average accuracy: 0.1936832493061916 Total samples: 4177\n"
     ]
    }
   ],
   "source": [
    "print(\"k-fold validation for 3\")    \n",
    "kfold(3,labels,features,classes,attribute_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there is a little improvement in accuracy. But still results are bad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
