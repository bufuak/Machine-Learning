{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply PCA to MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['time']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train features is: (60000, 28, 28)\n",
      "Flattened train in 0.8100388050079346 s\n",
      "Flattened train shape is: (60000, 784)\n",
      "(60000, 784) 60000\n",
      "Pca performed in 1.1720056533813477 s\n",
      "(2000, 45) 2000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "from time import time\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# PCA Implementation\n",
    "def pca(X): # I put a k parameter to choose number of pc\n",
    "    mean = np.zeros(len(X[0])) # It's just initializing mean vector   \n",
    "    for i in range(len(mean)):\n",
    "        total = 0\n",
    "        for row in X:\n",
    "            total += row[i]\n",
    "        mean[i]= total/len(X) # calculating mean for all columns\n",
    "        \n",
    "    Xsvd = X - mean # Centeralize the data\n",
    "    u, s, vh = np.linalg.svd(Xsvd, full_matrices=False) # Performing svd\n",
    "    PCs = u@diag(s) # Principal components are eigenvectors*eigenvalues\n",
    "    return mean,s,PCs # S vector is our eigenvalues, \n",
    "\n",
    "def loadData():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data() # We have load dataset, but our features are in 2-dim.\n",
    "\n",
    "    #Flattening our features\n",
    "    X_train = np.zeros((len(x_train),len(np.array(x_train[0]).flatten())))\n",
    "    print(\"Shape of train features is:\",x_train.shape)\n",
    "    t0 = time()\n",
    "    for i in range(0,len(x_train)): # Flatten train part\n",
    "        x_train[i] = np.array(x_train[i])\n",
    "        X_train[i] =(x_train[i].flatten())/255\n",
    "    print(\"Flattened train in\",time()-t0,\"s\")\n",
    "    print(\"Flattened train shape is:\",X_train.shape)\n",
    "    return X_train,y_train\n",
    "\n",
    "def pcaperform(features,labels,count):\n",
    "    if count>=len(features):\n",
    "        print (\"error\")\n",
    "        return -1\n",
    "    \n",
    "    t1 = time()\n",
    "    mean,values,PCs = pca(features[:count]) # Performed pca to 1000\n",
    "    print(\"Pca performed in\",time()-t1,\"s\")\n",
    "    \n",
    "    X = PCs[:count] # splitting data\n",
    "    Y = labels[:count]\n",
    "    \n",
    "    return X,Y\n",
    "\n",
    "features, labels = loadData()\n",
    "print(features.shape,labels.size)\n",
    "features, labels = pcaperform(features,labels,2000)\n",
    "features = features[:,0:45]\n",
    "print(features.shape,labels.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I performed pca to dataset's 2000 data. As we can see 2000 of them choosed. 784 PC exists. I Choosed 45 PC from last homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Help Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def performCluster(features,labels):\n",
    "    # do the clustering\n",
    "    kmeans = KMeans(n_clusters=10).fit(features)\n",
    "    cluster_labels = kmeans.labels_\n",
    "\n",
    "    cluster_matrix = numpy.zeros(shape=(10,10)) # Initilizing cluster matrix\n",
    "\n",
    "    for i in range(0,len(cluster_labels)):\n",
    "        cluster_matrix[labels[i]][cluster_labels[i]]+=1 # Creating cluster matrix\n",
    "\n",
    "    return cluster_matrix,kmeans # Return cluster matrix and cluster\n",
    "\n",
    "def findLabelsToClusters(cluster_matrix):\n",
    "    \n",
    "    maximums = np.zeros(shape=(100,3)) # Initilizng maximums\n",
    "\n",
    "    for i in range(0,10):\n",
    "        for j in range(0,10): # Creating maximums\n",
    "            index = i*10 + j\n",
    "            maximums[index][0]=cluster_matrix[i][j]\n",
    "            maximums[index][1]=i\n",
    "            maximums[index][2]=j\n",
    "\n",
    "    sorted_maximums = maximums[maximums[:,0].argsort()] # Sort it\n",
    "\n",
    "    label_cluster = np.zeros(10)\n",
    "    for i in range(0,10):\n",
    "        label_cluster[i] = -1 # to keep label-cluster relation\n",
    "\n",
    "    isFinished = 0\n",
    "    correct = 0\n",
    "    takenClusters = [] # To keep taken clusters\n",
    "    index = len(maximums)-1\n",
    "    while(isFinished <10):\n",
    "        label = sorted_maximums[index][1]\n",
    "        cluster = sorted_maximums[index][2]\n",
    "        if(label_cluster[int(label)]==-1): # If this label is not clustered\n",
    "            if(cluster not in takenClusters): # and this cluster is not taken\n",
    "                label_cluster[int(label)]=cluster # take this cluster\n",
    "                takenClusters.append(cluster)\n",
    "                correct += sorted_maximums[index][0]\n",
    "                isFinished += 1\n",
    "        index -=1\n",
    "    return(label_cluster,correct)\n",
    "\n",
    "def split(labels,features,n,k): # this function splits dataset using k-fold-cross-validation\n",
    "        train_labels = []\n",
    "        train_features = []\n",
    "        test_labels = []\n",
    "        test_features = []\n",
    "        \n",
    "        for i in range(0,len(labels)): # iterating dataset\n",
    "            # This condition works like this : goo.gl/images/WNkSSV n is our iteration number k is our splitting factor.\n",
    "            if i >= (len(labels)/k)*(n-1) and i < (len(labels)/k)*(n-1)+len(labels)/k: #splitting test data with n\n",
    "                test_labels.append(labels[i])                                          #nth test data is chosen\n",
    "                test_features.append(features[i])\n",
    "            else:\n",
    "                train_labels.append(labels[i])\n",
    "                train_features.append(features[i])\n",
    "                \n",
    "        return train_labels,train_features,test_labels,test_features # returning splitted datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kmeans with euclidian distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidian Distance\n",
      "Doing cross validation for 1 th\n",
      "Cluster matrix labels/clusters\n",
      "[[  0.   2.   1.   0.   0.   3.   7.  71.  68.   0.]\n",
      " [  0.   0.  72.   0.   3.   0.   0.   0.   0.  93.]\n",
      " [  0.  28.  21.   2.  12.  53.  13.   0.  11.  16.]\n",
      " [  6.   1.  19.   0.  12.   6. 101.   1.   4.   0.]\n",
      " [ 91.   3.  13.  13.   0.  45.   0.   0.   0.   5.]\n",
      " [ 15.   3.   4.   0.   6.  53.  58.   9.   2.   0.]\n",
      " [  3. 125.  19.   0.   0.   9.   2.   5.   0.   1.]\n",
      " [ 27.   1.  18. 112.   0.  15.   0.   0.   1.   8.]\n",
      " [  7.   2.  19.   1.  89.   7.  16.   0.   0.   1.]\n",
      " [ 65.   0.  20.  51.   1.  25.   1.   2.   0.   1.]] \n",
      "\n",
      "Labels to clusters indexes are labels, contents are clusters\n",
      "[7. 9. 5. 6. 0. 8. 1. 3. 4. 2.] with training error 0.473125\n",
      "Test accuracy is 0.4925 \n",
      "\n",
      "Doing cross validation for 2 th\n",
      "Cluster matrix labels/clusters\n",
      "[[  6.   0.   1.   2. 114.   0.   0.  14.  14.   0.]\n",
      " [  1.   0.   0.  71.   0. 101.   0.   0.   1.   0.]\n",
      " [  7.   3.   1.  16.   1.   7.   3.  16.  13.  92.]\n",
      " [ 23.   1.   1.  18.   0.   0.   3.  99.   8.   6.]\n",
      " [  0.   3.   2.  14.   0.   5. 120.   0.  30.   3.]\n",
      " [ 11.   0.   4.   7.   2.   0.   4.  54.  56.   0.]\n",
      " [  1.   0. 122.  13.   1.   4.   9.   3.   9.   1.]\n",
      " [  0. 116.   0.  19.   0.   6.  22.   1.  16.   0.]\n",
      " [ 79.   1.   1.  11.   0.   4.   3.  23.   7.   0.]\n",
      " [  2.  49.   0.  25.   2.   0.  70.   5.  17.   0.]] \n",
      "\n",
      "Labels to clusters indexes are labels, contents are clusters\n",
      "[4. 5. 9. 7. 6. 8. 2. 1. 0. 3.] with training error 0.5775\n",
      "Test accuracy is 0.53 \n",
      "\n",
      "Doing cross validation for 3 th\n",
      "Cluster matrix labels/clusters\n",
      "[[  0.   0. 122.   0.   3.   1.   5.   9.   8.   5.]\n",
      " [  0.   1.   0.  99.   0.   0.   0.   1.   0.  74.]\n",
      " [  2.   4.   0.  28.  76.   8.   5.   1.  11.  25.]\n",
      " [  3.   1.   1.   1.   0.  83.   8.  42.   1.  13.]\n",
      " [ 87.  16.   0.   5.  40.   0.   0.   0.   1.  17.]\n",
      " [  5.   1.   4.   0.   2.  21.  12.  42.   2.  59.]\n",
      " [ 10.   0.   2.   3.   2.   0.   1.   0. 121.  24.]\n",
      " [ 33. 114.   0.   8.   2.   0.   0.   1.   0.  10.]\n",
      " [  1.   1.   0.   5.   0.   1.  85.  35.   2.  11.]\n",
      " [ 68.  75.   1.   3.   3.   1.   3.   7.   1.  11.]] \n",
      "\n",
      "Labels to clusters indexes are labels, contents are clusters\n",
      "[2. 3. 4. 5. 0. 9. 8. 1. 6. 7.] with training error 0.533125\n",
      "Test accuracy is 0.5225 \n",
      "\n",
      "Doing cross validation for 4 th\n",
      "Cluster matrix labels/clusters\n",
      "[[  4.   7. 113.   0.   0.   7.   6.  19.   0.   2.]\n",
      " [ 78.   0.   0.   0. 103.   0.   0.   1.   0.   1.]\n",
      " [ 26.  86.   0.   4.  17.   1.   7.  16.   3.   1.]\n",
      " [ 11.   2.   1.   3.   0.  80.   1.  45.   2.   5.]\n",
      " [ 29.   2.   0. 105.   3.   0.   3.   0.  30.   0.]\n",
      " [ 45.   1.   3.   4.   0.  39.   2.  37.   1.   5.]\n",
      " [ 27.   1.   2.   4.   2.   0. 117.   2.   0.   1.]\n",
      " [ 26.   1.   0.  29.  11.   0.   1.   1. 112.   0.]\n",
      " [ 14.   0.   0.   2.   3.   2.   1.  32.   0.  81.]\n",
      " [ 27.   0.   2.  70.   2.   1.   1.   3.  61.   0.]] \n",
      "\n",
      "Labels to clusters indexes are labels, contents are clusters\n",
      "[2. 4. 1. 5. 3. 0. 6. 8. 9. 7.] with training error 0.528125\n",
      "Test accuracy is 0.5575 \n",
      "\n",
      "Doing cross validation for 5 th\n",
      "Cluster matrix labels/clusters\n",
      "[[  7.   0.   1.   3.  54.   0.   2.   0.  77.   6.]\n",
      " [  0.  99.   1.   1.   0.   0.  78.   1.   0.   0.]\n",
      " [  6.  10.   6.   6.   2.  86.  24.   5.   2.   9.]\n",
      " [  0.   0.   6.  72.  29.   2.  36.   2.   1.   4.]\n",
      " [  2.   5.  96.   0.   0.   2.   8.   9.   0.  49.]\n",
      " [  4.   0.  10.  35.  32.   1.  11.   0.   1.  53.]\n",
      " [107.   2.  18.   0.   4.   1.  14.   0.   0.   8.]\n",
      " [  0.   7.  32.   0.   0.   0.  15. 114.   1.  16.]\n",
      " [  3.   3.   7.  81.   9.   0.  27.   2.   0.   9.]\n",
      " [  0.   1.  58.   1.   3.   0.  15.  56.   1.  29.]] \n",
      "\n",
      "Labels to clusters indexes are labels, contents are clusters\n",
      "[8. 1. 5. 6. 2. 9. 0. 7. 3. 4.] with training error 0.47\n",
      "Test accuracy is 0.46 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Euclidian Distance\")\n",
    "for i in range(1,6): # do k-fold-validation\n",
    "    print(\"Doing cross validation for\",i,\"th\")\n",
    "    train_labels,train_features,test_labels,test_features = split(labels,features,i,5)\n",
    "    cluster_matrix,cluster = performCluster(train_features,train_labels)\n",
    "    print(\"Cluster matrix labels/clusters\")\n",
    "    print(cluster_matrix,\"\\n\")\n",
    "    label_cluster,correct = findLabelsToClusters(cluster_matrix)\n",
    "    print(\"Labels to clusters indexes are labels, contents are clusters\")\n",
    "    print(label_cluster,\"with training error\",correct/len(train_features))\n",
    "    predicts = cluster.predict(test_features)\n",
    "    correct_predicts = 0\n",
    "    index = 0\n",
    "    for predict in predicts:\n",
    "        if nonzero(label_cluster == predict)[0][0] == test_labels[index]:\n",
    "            correct_predicts += 1\n",
    "        index += 1\n",
    "    print(\"Test accuracy is\",correct_predicts/len(predicts),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine distance\n",
      "Doing cross validation for 1 th\n",
      "Cluster matrix labels/clusters\n",
      "[[  0.   3.   4.   2.  86.  57.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.  72.  94.   2.]\n",
      " [ 14.   3.  16.  23.   0.  50.   2.  20.  19.   9.]\n",
      " [  2.  41.  77.   0.   1.   9.   0.  11.   4.   5.]\n",
      " [117.   1.   0.   3.   1.   2.  21.  13.  12.   0.]\n",
      " [  3.  38.  35.   4.   7.  10.   1.   5.  35.  12.]\n",
      " [ 15.   1.   0. 122.  10.   4.   0.   7.   5.   0.]\n",
      " [ 25.   0.   0.   0.   2.   1. 119.  19.  16.   0.]\n",
      " [  1.  33.   3.   2.   0.   0.   1.   8.   8.  86.]\n",
      " [ 62.   8.   0.   1.   2.   1.  56.  19.  13.   4.]] \n",
      "\n",
      "Labels to clusters indexes are labels, contents are clusters\n",
      "[4. 8. 5. 2. 0. 1. 3. 6. 9. 7.] with training error 0.505\n",
      "Test accuracy is 0.5375 \n",
      "\n",
      "Doing cross validation for 2 th\n",
      "Cluster matrix labels/clusters\n",
      "[[  1.   1.   3.   3.   0. 138.   0.   4.   1.   0.]\n",
      " [  1.   0.   0.   0.   0.   0.   0.   1.  81.  91.]\n",
      " [  4.  17.  93.   4.   0.   2.   4.   5.  18.  12.]\n",
      " [  3. 108.   5.   1.   2.   3.   1.  15.  15.   6.]\n",
      " [ 83.   0.   3.   3.  70.   0.   0.   0.   8.  10.]\n",
      " [  5.  52.   0.   8.   3.   4.   0.  20.   3.  43.]\n",
      " [ 16.   0.   0. 127.   0.   5.   0.   0.   6.   9.]\n",
      " [ 18.   0.   0.   1.   5.   2. 127.   0.  16.  11.]\n",
      " [  4.  20.   0.   1.   3.   0.   1.  83.   8.   9.]\n",
      " [ 41.   5.   0.   0.  86.   2.  12.   5.  10.   9.]] \n",
      "\n",
      "Labels to clusters indexes are labels, contents are clusters\n",
      "[5. 9. 2. 1. 0. 8. 3. 6. 7. 4.] with training error 0.586875\n",
      "Test accuracy is 0.5725 \n",
      "\n",
      "Doing cross validation for 3 th\n",
      "Cluster matrix labels/clusters\n",
      "[[  0.   1.   0.   4. 139.   0.   4.   0.   4.   1.]\n",
      " [  1.   0.   0.   1.   0.   1.   0.  75.   0.  97.]\n",
      " [  3.   4.  90.  11.   1.   4.   3.  17.   1.  26.]\n",
      " [  4. 106.  10.   1.   3.   2.   2.  17.   8.   0.]\n",
      " [ 97.   0.   3.   2.   0.   5.  43.  11.   0.   5.]\n",
      " [  9.  57.   1.   4.   9.   1.  53.   6.   8.   0.]\n",
      " [  6.   0.   2. 136.   5.   0.   1.   6.   0.   7.]\n",
      " [ 33.   0.   1.   0.   0. 109.  10.   9.   0.   6.]\n",
      " [  5.  22.   0.   3.   1.   0.   1.  10.  92.   7.]\n",
      " [ 70.   5.   0.   1.   1.  61.  24.   8.   1.   2.]] \n",
      "\n",
      "Labels to clusters indexes are labels, contents are clusters\n",
      "[4. 9. 2. 1. 0. 6. 3. 5. 8. 7.] with training error 0.579375\n",
      "Test accuracy is 0.5825 \n",
      "\n",
      "Doing cross validation for 4 th\n",
      "Cluster matrix labels/clusters\n",
      "[[  1.   1.   9.   6.   0. 139.   0.   0.   0.   2.]\n",
      " [  1.   0.   0.   1.   0.   0.   0.  87.  93.   1.]\n",
      " [  4.  17.  89.   9.   1.   0.   5.  21.  14.   1.]\n",
      " [  7. 110.   5.   1.   1.   2.   2.  11.   3.   8.]\n",
      " [ 65.   0.   3.   6.  66.   0.  16.   9.   7.   0.]\n",
      " [  7.  55.   1.   8.   3.   7.   2.   6.  37.  11.]\n",
      " [ 14.   0.   1. 122.   0.   6.   0.   6.   7.   0.]\n",
      " [ 21.   0.   1.   1.  25.   1.  99.  19.  13.   1.]\n",
      " [  7.  22.   1.   0.   3.   0.   0.  11.   7.  84.]\n",
      " [ 42.   2.   0.   1.  80.   2.  23.   7.   9.   1.]] \n",
      "\n",
      "Labels to clusters indexes are labels, contents are clusters\n",
      "[5. 8. 2. 1. 0. 7. 3. 6. 9. 4.] with training error 0.554375\n",
      "Test accuracy is 0.5675 \n",
      "\n",
      "Doing cross validation for 5 th\n",
      "Cluster matrix labels/clusters\n",
      "[[  0.  65.   0.   4.  75.   0.   4.   0.   2.   0.]\n",
      " [  1.   0.   0.   1.   0.   0.   0.   1.  78.  99.]\n",
      " [  2.   2.  91.  10.   3.   5.   3.   5.  14.  21.]\n",
      " [  5.  49.   0.   0.  52.   1.   3.  17.  24.   1.]\n",
      " [ 94.   0.   4.   3.   0.   8.  48.   0.   8.   6.]\n",
      " [  4.  44.   1.   5.  26.   1.  46.  11.   8.   1.]\n",
      " [ 11.   4.   1. 121.   1.   0.   3.   0.   9.   4.]\n",
      " [ 31.   0.   1.   0.   2. 115.  15.   0.  13.   8.]\n",
      " [  3.  13.   0.   2.   1.   1.   4.  92.  17.   8.]\n",
      " [ 55.   4.   1.   1.   1.  58.  28.   1.  14.   1.]] \n",
      "\n",
      "Labels to clusters indexes are labels, contents are clusters\n",
      "[4. 9. 2. 1. 0. 6. 3. 5. 7. 8.] with training error 0.4975\n",
      "Test accuracy is 0.5025 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.cluster.kmeans import KMeansClusterer\n",
    "import nltk\n",
    "def performCluster(features,labels):\n",
    "    # do the clustering\n",
    "    \n",
    "    kclusterer = KMeansClusterer(10, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "    cluster_labels = kclusterer.cluster(features,assign_clusters=True)\n",
    "    cluster_matrix = numpy.zeros(shape=(10,10)) # Initilizing cluster matrix\n",
    "\n",
    "    for i in range(0,len(cluster_labels)):\n",
    "        cluster_matrix[labels[i]][cluster_labels[i]]+=1 # Creating cluster matrix\n",
    "\n",
    "    return cluster_matrix,kclusterer # Return cluster matrix and cluster\n",
    "\n",
    "print(\"Cosine distance\")\n",
    "for i in range(1,6): # do k-fold-validation\n",
    "    print(\"Doing cross validation for\",i,\"th\")\n",
    "    train_labels,train_features,test_labels,test_features = split(labels,features,i,5)\n",
    "    cluster_matrix,cluster = performCluster(train_features,train_labels)\n",
    "    print(\"Cluster matrix labels/clusters\")\n",
    "    print(cluster_matrix,\"\\n\")\n",
    "    label_cluster,correct = findLabelsToClusters(cluster_matrix)\n",
    "    print(\"Labels to clusters indexes are labels, contents are clusters\")\n",
    "    print(label_cluster,\"with training error\",correct/len(train_features))\n",
    "    predicts = []\n",
    "    for feature in test_features:\n",
    "        predicts.append(cluster.classify(feature))\n",
    "    correct_predicts = 0\n",
    "    index = 0\n",
    "    for predict in predicts:\n",
    "        if nonzero(label_cluster == predict)[0][0] == test_labels[index]:\n",
    "            correct_predicts += 1\n",
    "        index += 1\n",
    "    print(\"Test accuracy is\",correct_predicts/len(predicts),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
